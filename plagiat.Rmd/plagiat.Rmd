Base Header Level: 1
Title: Sociocultural Boundaries and the Survival of Knowledge
Author: Brooks Ambrose

Brooks Ambrose

941 Hayes St.

San Francisco, CA

94117

(610) 304-0318

bambrose@ucla.edu

Dissertation Committee

Lynne G. Zucker, Co-Chair

UCLA Sociology

Gabriel Rossman, Co-Chair

UCLA Sociology

Barbara Lawrence

Anderson Graduate School of Management

Jacob Foster

UCLA Sociology

8,378 words.

SOCIOCULTURAL BOUNDARIES AND THE SURVIVAL OF KNOWLEDGE

by Brooks Ambrose

----

## **Introduction** ##

```{r global_options, include=FALSE}

knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',echo=FALSE, warning=FALSE, message=FALSE)

```

### **NEOCLASSICAL SOCIOLOGY** ###

This study makes occasional reference to Weber, Marx, and Durkheim, which is a currency of variable worth in sociology. These references are incidental to the meaning of the text, but may help the reader familiar with their work to understand deeper motivations for a kind of sociology that gives equal credence to problems of culture and social structure, even if methodological limitations tend to favor the latter over the former.

### **WHAT DO NETWORKS MEASURE?** ###

We treat networks as measurement devices only. Networks are not real objects in the world, rather they are useful data structures to capture common features of what may otherwise be very different phenomena. We wish to be explicit about our resistance to the reification of networks, a tendency that is reinforced by field of network science. Sociologists should do more work to achieve clarity on what it is we think networks are measuring. This is the ontological dimension of the sociology of networks.

We make a prima facie case that the distinction in network methodology between node (a.k.a. vertex) and tie (a.k.a. link, edge, arc) may usefully be mapped to the distinction between social and cultural objects. The data structure reinforces an old sociological argument that human relationships are never unmediated. By allowing units to bear a relationship that can be independently measured, networks differ fundamentally in their ontology than the stochastic data model, where units only bear qualities and are otherwise treated as if they are independent.

----

## **Chapter 1** ##

### **ABSTRACT** ###

### **INTRODUCTION** ###

This paper studies two central problems in the sociology of networks, the role of culture in the mediation of social ties, and the relationship between population research methods and the topography of large scale networks. The history of scholarship is a topic that provides several strategic research materials {Merton:1987vi} for the examination of these problems. Digital archives of scholarship, some of which contain more than a century's worth of information, allow easy observation of cultural objects apart from the social organizations that create them. These archives represent an opportunity to explore the interdependencies between culture and social structure.

The history of scholarship is a case belonging to the sociology of the production of culture alongside other studies of art, science, and entertainment. Cultural products are easier to observe than their social conditions of production, since in these industrialized and commodified fields culture is produced for the purpose of distribution though not necessarily profit. By observing how cultural products hang together via the diffusion of their elements and the acts of reference of their authors it may be possible to observe indirectly the social organizations that underlie cultural productivity. Put differently, the morphology of culture may provide a scope for the detection of invisible colleges.

We need not treat cultural boundaries as if they were social boundaries if we have independent measurements of social organizations, such as, for example, what may be inferred to lay behind data about the flow of money from grantors to grantees. However, even in a rich data environment, the lion's share of social organization remains invisible and ever harder to measure as events recede into history. Like the archeologist we cannot avoid studying the imprint that social organization makes in a more visible cultural record.

In order to detect social organization when our data are traces of cultural expression, we exploit the relational aspects of cultural objects, or the tendency of cultural units to hang together in parcels. Where such parcels exist, this is evidence that a generative cultural mechanism exists that orders these units such that their boundary is maintained against an incredibly fluid set of expressive possibilities that is constantly at play by a gregarious humanity. Such ordering is exogenous to "pure" cultural play, where in lieu of expression in common we are rather treated to a parade of idiosyncrasies. In short, culture, i.e. common and recognizable expression, is a consequence of social organization. The maintenance of a boundary around the use of particular cultural objects in particular configurations of other cultural objects is the observable feature of this otherwise invisible sociocultural phenomenon.

Network methods are excellent tools to show us just how unlikely it is that, if the assumptions of creativity and gregariousness were true, cultural objects would hang together exactly as they do.

Discuss node and tie as primary data, and boundaries as inferred from their pattern.

What is tied and therefore boundable and also what constitutes the ties themselves are undertheorized problems in the sociology of networks, but their exploration is also an envoy to more basic questions in theoretical sociology concerning the relationship of culture and social structure. Much more attention has been paid to network morphology, and indeed this is the most abstracted form of network science. Sociologists have an important contribution to make in policing the meaning of a network tie, which has metric as well as ontological dimensions. The technique of this study is to infer boundedness from network data about cultural ties, and to treat cultural boundaries as our best indicators of invisible social organizations. A controversial result of this approach is that once the argument is established its inverse is equally valid, that social boundaries are our best indicators of invisible cultural organizations. The argument is that social organizations and cultural organizations constitute each other, that social units are tied by culture and that cultural units are tied by sociality.

While we have an easier time treating social organizations as real, it has been more difficult for sociologists to treat cultural organizations as real. Perhaps because of the individualism of liberal culture or the bureaucratization of life in liberal societies, membership in a social organization does not appear to irreversibly reduce the individual to her role. There is however much more vigilance against categorizing individuals as members of a culture to guard against the threat of cultural essentialism, which we fear may violently reduce the individual or enroll them in sometimes insidious forms of acculturation.

Where common cultural expressions are taken as indicators of relationships among persons, the networks so constituted differ in important ways from classical Granovetterian models and are especially distinct from the small worlds image of networks. Culture is thick, and as an indication of relatedness, its measurement tends to lead to large worlds. The large world model has continents that are highly cohesive internally and relatively closed externally. Thus the partition of the network into cohesive regions—clusters, small worlds, etc.—and sparse regions—structural holes—is still useful but it is not enough, and methods to explore differential patterns of cohesion are necessary to uncover the hidden structure of the continental parts of the graph.

Imagine that a researcher had the capacity to accurately record natural human expression at a macroscopic scale and to relate persons based on the expressions they have in common, or conversely, to relate expressions based on the persons they have in common. Given the proclivity of humans to express themselves we can imagine how thick a network so constituted would be.

This hanging together involves elucidating centers of cultural activity and the sparse borders between them. There is an error, however, in treating cultural boundaries as if they are social boundaries. . .

This second notion of boundary is not so strong a barrier in a cultural sense. These are stratification boundaries, the existence of a categorical separation without the distance characteristics of segmentation boundaries. Strata are adjacent, and travel between strata may occur if their transection is possible. Still, stratification boundaries may be just as effective at impeding mobility as segmentation boundaries. The paradox is that, where....., ties may appear to flow freely across borders. The paradox may be resolved by the concept of a coherence gate, which can be crossed only if the traveler is carrying at least the minimum number of keys (ties) required to "unlock" access to the interior protected by the gate. For instance, if a border can be crossed through five ties but only four are available, a barrier exists in conjunction with strong ties across the boundary that it forms. The arbitrariness of such a boundary may require outside force to maintain, but such arbitrariness is certainly in the wheelhouse of especially social forms of authority and organization.

[evidence on status:value]

Each of these types of boundary may be used to enumerate a population of socially and culturally discrete units and to keep track of their interdependencies. It is an old application of network methods to reduce tie information to a set of categorical memberships. Network clustering and cohesion methods have long accomplished this task. In small networks, such methods tend to produce a concomitantly small set of memberships. However, in a large world network, one that like ours includes thousands of people over a century of development, clustering and cohesion techniques more accurately enumerate a new kind of population, a population of socially stratified subcultures. This is the hinge between sociocultural networks and a population and stratification approach to studying fields of cultural production.

Recent advances in computing power and the development of efficient algorithms for interrogating clustering and cohesion open a door for new quantitative studies of culturally mediated social networks, or as we will discuss, through the inverse operations socially mediated cultural networks.

[theory of development / life cycle of commodified cultures]

Life cycle of subcultures. How do they emerge, become institutionalized, and eventually decline?

[...elaborate...]

### **BOUNDEDNESS** ###

Human action is always a complex outcome of a mechanism involving social conditions, cultural interpretations, and personal idiosyncrasies. Sociologists tend to not be able to assess each aspect simultaneously, either because the researcher is not interested in each or because data are available for one but not for the other two. Theories and genre classifications within sociology often sanctify and reinforce these biases.

Following a macroscopic view of action actors are necessarily thrown into interference with each other under the assumption of scarce resources. The investigation here explores Boundaries are one feature of Boundaries have an effect in these mechanisms that is best revealed by the counterfactual consequences of their absence. Further, boundaries Social conditions may There can be no causal separation of these components in the 

Sociocultural boundaries are the consequence of both cultural and social processes and they are therefore unidentified empirically. There is no such thing as endogenous or exogenous cultural causation 

The image of boundaries here is isomorphic in certain respects to Durkheim's discussion of the relationship between dynamic and material density.

*Three Theories* A description of an empirical boundary is not a characterization of why it exists or where the boundary comes from. There are many theories of social processes that create boundaries. Here we consider three, the new institutional theory of symbolic classification, Bourdieu's theory of distinctions in a social space, and Weber's theory of cultural logic, and we make some attempt to map the theories that underlay a few of the methodological tools that researchers may use to empirically investigate boundaries.

*Social Space*. To begin it will be useful to consider a theory that is diametrically opposed to the classification of groups. We find one in Bourdieu's essay, *The Social Space and the Genesis of Groups* {*Bourdieu:1985wh}. Bourdieu claims that marxian social class categories, and their implied boundaries, are analytical constructs with no real referent in the world. The rules for placing an uncategorized actor into a class are well established in any number of class theory traditions. The rules relate to attributes of the actor which may be independently measured, e.g. does she sell labor or buy it? If she sells it, she is a proletarian, if she buys it she is a bourgeoise. Because these categorical rules are the analyst's, Bourdieu decries the reification of the boundary between classes so constituted.

Bourdieu's outcry may be unfair. In the development of a scientific theory, what Bourdieu refers to as a reification may be more graciously described as a classification analysis. Boulding {/*Boulding:1956wd/ :202} usefully organized these different analytical forms into a typology of theoretical complexity. [^fn1] What Boulding calls a framework is a static classification in which the relationships among elements may be ignored because they do not change the characteristics of elements. No phenomenon in the world is actually static; a framework is merely a useful simplification of phenomena that are slow changing or robust with respect to other elements that happen to be included in the analysis. From a practical standpoint, a framework is a useful first step in an empirical investigation that allows the analyst to bin observations into coarse categories that at least genuflect to unexplored relationships among categories. [^fn2] A critic, like Bourdieu, may accuse another analyst of improperly applying a framework where a more complicated analysis is necessary. In Boulding's typology, the next level of theory is the clockwork, which is a reference to classical mechanics. When the analyst categorizes an observation into a A clockwork imposes relational consequences on elements that understand the mechanisms that relate types . Bourdieu is indeed offering a clockwork theory, one that inscribes social relationships in a dynamic space of opposing forces. This metaphor of the social world as a physical system would, according to Boulding, be a simplification of human systems that diminishes their special characteristics. Bourdieu no doubt 

Rather than a multidimensional multinomial space, Bourdieu argues that people actually exist in the world in a multidimensional euclidean space, where, in capitalism at least, dimensions are defined by forms of capital. [^fn3] Money, for instance, may be used to place people on a scale and the difference in their holding defines their distance along one dimension of that space.

Bourdieu suggests a particular cartesian dimensionality, where the first scale is equal to capital holdings summed across all forms of capital in a society, and where the second scale is the "composition of their capital...the relative weight of the different kinds of assets within their total assets {/*Bourdieu:1985wh/ :725}. Bourdieu wishes to measure absolute social positions, or the macroscopic social structure of a society. A better idea is to deal directly with a multidimensional space where each scale is appropriate to its form of capital. Clustering, for instance, would identify groups high or low on every scale.

Murkier is Bourdieu's notion of relationship. This image of a social position within a space then serves for Bourdieu as a structure within which relationships form. Such relationships are steered by the actors involved but are heavily conditioned by their capital holdings. Social distance does not necessarily imply an absence of relationships; rather it implies an asymmetry of power in a manifest or latent relationship. In field theory a relationship tends to be a competitive bid for profit in a field constituted by a form of capital. 

Bourdieu fails to circle back to the starting point, where he eschews categorical distinctions. The social space model, however, begs the question of clustering and the re-emergence of categorical distinctions. Presumably, the social space model allows for either outcome: people may be distributed relatively evenly or even randomly across each of dimension, or they may cluster in groups. If groups are discernible, the question may then be asked whether categorical classifications are valid.

*Field*.

*Games*. Imagine a fence separating two fields, and a gaggle of players on each. What will condition how many games will be played? Zero is the least, but only an extreme kind of condition would yield this. One game is possible, but it would require including the fence as a feature of the game. Perhaps two is natural, divided by the fence and establishing it as a boundary condition. But two across the fence is also a possibility, in which case it is not a boundary.

What is the next landmark in the number of games that can be played? Suppose there are ten on one side of the fence and six on the other. We might imagine a series of subdivided groups cordoning themselves off from one another. The fence is an incidental part of this structure. Though groups across the fence from each other may be ignorable due to an endogenous boundary condition, groups on the same side of the fence must establish their boundaries internally. In so doing they may achieve the illusion of natural separateness even though they must actively maintain the separation.

If one is a player then she has the chance to observe the game while it is being played; when one does not understand the game then she cannot decipher the game from the play.

Assume that we know none of the games being played. What then can we rightfully observe? Is it possible at least to enumerate the games being played? What makes this possible?

Fundamentally, we can rely on two forms of embeddings for games. The first is most immediate and accurate: the boundary conditions of the game will always be visible, and indeed we may argue tautologically that play that cannot be delineated by an observer can also not be delineated by the players. This limiting case of cryptic play imposes on itself the inability to recruit both players and audiences.

The second observable may not always be taken for granted. The objective tokens of play pass through stages of maturity; initially, and especially when players are inventing the game through a partial exploration of the objective features of their extant tokens of play, the maneuvers of the game may involve several substitutable tokens to fill the same element of play. Wittgenstein on language games.

, and counts as their boundary conditions and the objective tokens of their 

Bourdieu produced a strong version of the critique; if one cannot understand the game she cannot be a scientist. All she can do is impose an alien classification scheme.

*Genre*. Following the production of culture (POC) approach {Peterson:2004ux}, Lena and Peterson "defocalize text and place the study of genre squarely in a social context" {/*Lena:2008er/ :698}. POC makes a strong claim, as Durkheim {*Durkheim:1965uu} did, that many cultures can be usefully reduced to a set of social relationships. This study by necessity follows the same path, but not because we believe that cultures fail to influence social structures according to their own logics {c.f. /*Weber:1996ux/}. Indeed 

Genre theory, an application of classification theory {Dimaggio:1987vr}, treats genre distinctions as "phenomena where individuals and groups construct cultural boundaries" {/Lena:2008er/ :698}. Lena and Peterson summarize a large literature on music genres by organizing vignettes about musics and the social locations where they are found first into genres and second into a stage-sequential developmental typology. [^fn4] The archetypical developmental pattern has four stages: avant-garde, scene-based, industry-based, and traditionalist (AgSIT).

A genre is ostensibly born in the avant-garde, where, in an effort to do something new, musicians including amateurs simply produce at their given capacity. The resources they bring to bear generate some level of object production. In hearing their own music, what must also be present is a sense of taste. There must therefore be a pre-avant-garde stage of production without taste, of mere play for their own amusement and with not expectation that they will develop influence, that others will regard what they do as a legitimate class of activity for which they may earn respect, or at least recognition. It is essential then that legitimation theory be yolked to genre theory, as it must have been in the authors reading of the literature. But Lena and Peterson genuflect to the underlying mechanisms, giving opportunity for these theories to be developed. This is beyond the scope.

What is in scope is a characterization of the developmental sequence. It implies a morphodynamic problem that could lead to misidentification of boundaries. Say a large boundary is carved out historically; within this boundary segmentation may trick a boundary detection method into thinking there are many units, when indeed there are, but also a larger unit defining the developmental trajectory. To see a person as a child, adult, and not the same person may indeed be valid. We treat those moments as separate units who live and day according to a clock that is not so regular as it is for living things.

POC is better thought of as a theory that is correct within certain scope conditions. The assumption that culture can be ignored is systematically related to the affinity of POC for the study of industrial commodity production, where business relationships develop precisely to be be robust to problems of cultural meaning. Hirsch {*Hirsch:1972fm} describes that through organizational throughput businesses ignore meaning by arranging auctions among producers who cannot ignore it, because their understand of meaning is an important factor in the production process. From the businesses perspective they need only arrange the entire market of producers into an auction for the scare resource of distribution. This selection boundary enables them to achieve high quality cultural content without understanding it. The only check on this willful unintelligibility of the product is a concern with the quantity of demand of it, but marketing in large markets obviates the need for taste in the development of a market, since people can be told what to like. Such a process finds its apex in the phenomena of genre classifications, which exist as the cultural articulation point between the production and consumption of culture. Not only do genres constitute the tastes of consumers, as they develop opportunity structures within them the force of social stratification in capitalist societies they have an inexorable effect ton the tastes of producers. Productive ability becomes generalized and is no longer wed to the development of taste. In this situation of industrialized culture, monastic cells are paradoxically given a special kind of power, free reign due to the scarcity of taste.

*Toolkit*.  The assumption that cultural structures are more durable than social structures differs markedly from toolkit theories.

*Dynamic Density*.

*Three Methods* If there is a nuance to be found in this work it is to pay greater attention to the problem of establishing the units of analysis.

*Bounding Methods*. Sociologists tend to decide unit boundaries definitionally, which is to say non-metrically.

*Community Detection*. All community detection methods assumes that ties are driven by an unobserved set of groups and each proposes a procedure to uncover those groups. What is really being interrogated in each case is the existence of boundaries between sets of nodes. One set of methods uses the modularity measure introduced by {REF} to adjudicate among proposed boundary configurations. Modularity 

is class of network methods that reduces tie information into category membership. , like cluster analysis or latent variable regression approaches that use conventional flat-file data, synthesize information about ties among nodes into higher level constructs about group membership.

I use a method called

*Modularity*. Modularity Classes

Modularity as a metric is the outcome of a function that takes a given community structure, e.g. one fed in iteration to an algorithm, and compares it to the same network if it were randomly reorganized. Modularity is a value between -1 and 1 and is equal to the proportion of ties within community boundaries minus the proportion of ties within the same boundaries when ties are randomly reassigned. A community structure with a value of 0 refers to a structure that could appear at random. A positive score means that the structure captures more internal ties than we would expect at random. A negative score means that the structure cuts against the real organization, that random ties would be more likely to occur within than across boundaries. Modularity methods each attempt to find "the" boundary configuration that has the maximal modularity score, and they differ either in how they simulate the random network or in how efficiently they explore the set of all boundary configurations.

Shwed and Bearman have treated modularity as an operationalization of the concept of "consensus" in scientific communities, implying that it measures the same thing across networks. If two networks have similar modularity scores for their respective maximal boundary configurations then we know

Networks with the same modularity score Contrary to Shwed and Bearman {*Shwed:2010kv}, modularity does not have generalizable meaning because it is based on a comparison to a null network that must resemble the real network on parameters such as size, density and degree distribution.

Fortunato (2010) provides a useful review of accomplishments in the field of community detection in networks. Community detection refers to a set of techniques that attempt to locate sets of nodes that have more external than internal ties. The field is characterized by diversity in the theoretical characterization of what "communities" should mean analytically and how communities should be algorithmically constructed given real or simulated network data. The concept of modularity provides a standard against which alternative theories and computational solutions can be compared and evaluated. There are two broad categories of community detection techniques: "agglomerative" algorithms collapse sets of high degree, high density nodes recursively, and "divisive" algorithms remove links between nodes with high "betweeness", discovering communities by breaking weak ties between them. (Blondel et. al. 2008: 2, Jackson 2008: 444) Both techniques continue iteratively and eventually reach a limit where they have either collapsed the entire network into one node or they have completely dissolved all network connections. The analyst may choose a desirable point to stop the algorithm, for instance, by specifying the expected number of communities, but most applications use the concept of "modularity" to provide an objective stopping point.

An additional methodological difficulty is the fact that the algorithm does not produce an unequivocal community structure. As a maximization function, it is sensitive to local maxima that might be lower than the global maximum. The problem manifests itself in that some articles at the "edge" of a community will oscillate randomly across the boundary depending on starting point of the algorithm. To mitigate this effect, the starting point can be randomized, the algorithm can be repeated, and then the highest modularity can be chosen from the set of trials. A more sophisticiated technique is to use this variability to one's advantage by capturing information about the oscillations of particular nodes among different clusters, thus constructing a measure of cluster overlap or the interstitial locations of particular nodes.

*k-clique percolation*. k-clique percolation, which has several advantages. First, unlike modularity-based methods that use randomization, clique percolation is determinate and reproducible, like the link-community method utilizing the tanimoto coefficient. It is reasonably fast on large networks. It is also well-suited to the design of a co-reference network, in which the reference page of an article is represented as a k-clique of citations where k is equal to the number of references.

Construction of

*Topic Modeling*.

*Analytical Methods*.

*Survival Analysis*.

### **AN EMPIRICAL APPROACH** ###

*Identity Uncertainty* papers isn't working: paper on identity uncertainty, Pasula et al

*Decision Rules for Variations*. Sorting through millions of citation variations is not impossible, but much of this process can be automated. TR WOK citation codes follow several patterns that can be exploited. Here we have tried to establish a parsimonious set of rules that will allow the computer to treat as identical those sets that are likely to contain only one variation, leaving the more problematic cases to the discretion of a human coder. These are the rules:

For each citation, the following information was measured if present:

-The year, volume, and page, and character count.

-The date in seconds from January 1, 1960 if coded as a daily serial.

-The minimum similarity score associated with it.

For each set of citations, the above measures were collapsed into minimum and maximum values and standard deviations. The number of citations in a set were also recorded. Especially to aid decisions in the case of corporate author sources, discussed below, a measure was taken to determine if years within a set were consecutive, as in the case of annual reports that should be treated discretely.

Each of these absolute scores were then commensurated by conversion into percentile ranks. In general, citation sets that fell into the lowest percentiles (highest for character count and set size) were regarded as most unproblematic. If one computed an average percentile score for all nonmissing measures, and sorted the list of sets, time could be minimized by having the coder look at the most problematic sets first. Beyond a certain threshold, a coder could safely assume that the remaining sets were valid.

Commensuration by percentiles may obscure natural thresholds in the data, thus histograms were observed to locate such cut points.

To increase our accuracy, we can exploit categorical distinctions among citations, which may be to books, journals, non-journal serials, and corporate authors. The following rules let us treat these cases more carefully.

To identify books:

1. Each citation must begin with a letter, which is assumed to be the author.

2. A volume number cannot exceed 3.

3. 

Journals:

1. Each citation must have a volume and page numbers.

Other serials:

1. Citation must have a four digit day-month code.

Corporate authors:

1. Citation must begin with an asterisk.

Treating these categories separately helps coders move more quickly by allowing them to remain in a particular human coding routine. Below we document a full protocol for each category, and add rules as we discover them to be useful.

We begin with books.

For periodicals, we simply treat as identical sets whose standard deviation of dates is three days or less.

*Machine Learning*. {Domingos:2012jz}

#### *Sociocultural Networks* ####

#### *Nested k-clique community structure* ####

### **CONCLUSION** ###

----

## **Chapter 2** ##

### **INTRODUCTION** ###

### **DATA** ###

The raw data for this analysis are from the Thompson Reuters Web of Knowledge Social Science Citation Index. Ideally, we would analyze the entire stock of recorded publication material to give the best chance of observing when authors contravene institutional boundaries. Practically, we must take a sample, however sampled networks are not small versions of the population network {Handcock:2010iw}. Sampling may have the effect of degrading the network cohesion on which community detection methods depend, such that a method will not detect the same boundaries in a sample as it would in the population. To avoid a sampling effect on network cohesion, we draw a full census of articles, reviews, and book reviews from each journal selected.

Sampling on journals creates another problem, which is to merely reproduce boundaries coextensive with the journals from which the articles are drawn. Even though journals market themselves at catering to particular disciplines and subfields, we should not assume that authors, editors, and reviewers always obey these distinctions. If a scholarly field exists with a grounding in two more journals, the omission of one may also degrade its cohesion to the point of rendering its boundaries undetectable. As an indicator of affiliation among journals, we use Leydesdorff's {/*Leydesdorff:2010ci/ :}

We should also expect to observe boundaries due to several other institutional levels higher than journals, like publishers, disciplines, or national and language groups. which is To provide ample opportunity to observe boundaries existing in the space between journals and between academic disciplines, we also take a large sample of journals

To observe some of these high level institutions, we draw sets of journals from four social science disciplines–anthropology, sociology, economics, and political science–and we draw these in blocks from the same publisher. Journals were selected from the disciplinary affiliations signaled in their titles. From a JSTOR master list of archived materials, journals were selected if they contained any of the disciplinary prefixes anth-, soci-, e[ck]on-, and poli-. [^fn5] This list was cross referenced with the TR WOK database.

#### *Population Descriptions* ####

TABLE X ABOUT HERE

Table X describes the sample of TR WOK records by their journal and publisher membership. These records contain information about several different kinds of units in the scholarly field. In real settings, there may be a scale free relationship between sorting and sorted units in that depending on the relationship the same concrete unit may be a sorter or a sortee. We describe five low level units–authors, documents, pages, references, and citations–and three high level units–publishers, journals, and document types–into which the former are distributed. Later, we will add another high level unit, the citation community, which will be derived from the citation relationships among documents. 

A TR WOK record measures several variables about the article and its journal, and it includes a coding of the citations in its reference page. Though the terms are synonyms, for clarity we will refer to a reference as the unique work itself and a citation as an author's inclusion of that work in her reference page. The population of articles is equal to the number of TR WOK records, but there are two populations to consider in the case of citations. The population of works referenced by any article is the unique number of citations among them, while the population of acts of reference is equal to the sum of the length of each page of citations. The reference population is larger because many citations are referenced more than once. Because of the censorship inherent in reliance on WOK records, the citation population cannot be smaller than the reference population. Because we only observe citations that were referenced at least once, the population of works that are referred to but never cited are unfortunately censored. We will recover this notion of relevant and uncited work when we discuss the proximity of references in a citation networks. There it will be possible to identify references that were not cited as well as the authors who might have cited them.

Though we sometimes refer to all WOK records as articles, we actually use article, review, and book review records. While we focus on journals, we also use book review records to make it more likely that we include books relevant to the work of journal authors. While book reviews normally only include a single reference to the reviewed work, this reference will increase the degree of the book as a node in a reference network. Because we make selection decisions on the basis of degree, book reviews help add weight to works that might otherwise have been discarded. The distinction between an article and a review may be twofold. First, reviews tend to have much longer reference lists than articles, and we will see that reference count has an exponential impact on the network. Secondly and partially as function of their high degree, reviews also tend to bridge small worlds within the network.

#### *Network Selection* ####

We have described population characteristics of four kinds of cultural units that may be identified in TR WOK records. The use of co-citations as a measure of affiliation among articles forces a large selection effect on the article population. Because they provide no relational information in this sense, we omit articles that make no citations. It was not uncommon early in the century for articles to make no citations, either because they were short comments or because referencing in the much smaller academic world of the time was possible by informal acknowledgements in the text. [^fn6]Eleven percent of articles are not selected because they make no citation and therefore no contribution to network structure.

A second criterion of selection concerns the status of references that are only cited once, which are the vast majority (94 percent) of references. As a statement about the boundary between personal and cultural meaning, we may note that nineteen in twenty resources are meaningful to individuals and yet are so much flotsam and jetsam to the projected culture of a community. We omit this large body of references both because as meaningful objects they are idiosyncratic, meaning something to only one project, and because they do not provide information in a network sense. This carries a risk of selecting against citations that were culturally relevant and yet were not picked up by the community, but many of these singletons are citations to data rather than to scholarship of general significance {/Cole:1983vd/ :127}. In a secondary analysis, we will predict the relative prevalence of (culturally) meaningful and meaningless singletons by making assumptions about the distribution of citation counts. We will however be unable to distinguish which singletons are in which category, so the relational information they would add to a network analysis is lost with or without this exercise.

#### *Coding Variations* ####

Some singletons exist only because of codification errors. These may be address errors, where the original author miscoded or incompletely coded the reference, while others are the data coding errors of WOK workers. Authors behavior toward citations in two ways. When they have read and can remember the original reference, an author may treat the citation as a sign that evokes the text for herself and her audience. When she requires the citations to locate the text, it acts like the street address of building. When an author writes a reference as a sign, she may be less concerned with its accuracy as an address, and this, along with database errors, will lead to variations in the coding of a reference in TR WOK data. As it may still be possible to locate a home with only a partially correct or complete address, a poorly coded reference may still be enough to lead a researcher to the correct reference; it may just as well lead her on a goose chase.

One must decide how to represent citations variations computationally. Some errors may be corrected using record matching techniques. The Levenshtein string distance, or the number of transformations required to turn one character string into another, can be used to identify citation codes that are nearly identical. This should be done to correct artificial database entry errors, as network methods tend to not be robust to node and edge identification errors. Natural address errors require a decision. If historically scholars successfully perceived two versions of a citation as signs to the same text, then we should correct the codes even if they were actually different in historical documents. If the addresses were so wrong as to lose one searching for the reference, then they should remain as different in the data. The Levenshtein distance is an appropriate measure of this distinction. If two codes to the same reference have a close Levenshtein distance, then it is reasonable to assume that historical actors would have perceived their identity. If they are far, however, then we should allow them to fool the computer as they would have fooled an historical actor. By performing hierarchical clustering of these string distances, sets of variations can be used to assign consistent codes to members of the set. The threshold at which one stops clustering citations represents the standard beyond which their identity is unrecognizable. We use the same procedure to handle variations in the coding of author names. In both the citation and author name case, we manually verify the contents of each set, and we train the algorithm to be sensitive to small differences that make a big difference, such as a one unit change in the volume number of a journal or two author names that have a different middle initial. Historically the problem of natural variations abates due to the institutionalization of a norm of accuracy as a feature of scholarly professionalization. Those that remain are database errors and should be corrected.

#### *Network Description* ####

Researchers often interpret reference data as indicating a deference tie from the citing to the cited paper or an influence tie in the opposite direction. We have a different concept of the meaning of these data. The citing paper represents the consummation of a social project in the face of particular historical and sociological constraints. It represents successful social productivity, both in the research of the paper and in the navigation of the publication process. It is a special intersection of social and cultural processes, where the scope of cultural meaning is restricted to what counts within the reward system of science. The cited paper, on the other hand, is a member of a set of cultural resources that endures historically and is only ever partially exploited at a historical moment. Compared to the crop of new articles published in a particular year, the class to which the cited reference belongs is much larger in scope and represents both accumulated knowledge and a grammar of communicative possibilities within which innovations are developed. Much of the sociology of science is concerned with the exploration of and creative destruction of this historical stock of knowledge.

We make to operational decisions to represent the stock of knowledge as distinct from its exploitation. The first is to project the TR data as a bipartite or two-mode affiliation network in which intermode ties are allowed and intramode ties disallowed. By assigning citing and cited article each to a different mode we maintain the ontological distinction between them and condition how each can relate to the other. A cited article is affiliated indirectly with another cited article only if each is used in the same citing article. Similarly, citing articles are affiliated by having cited one or more of the same reference. In this two-mode framework, it is possible that the same article can be represented in each mode, once as a project and once as a resource for other projects. For simplicity we will call the first mode the article and the second the reference.

Two-mode data is sometimes referred to as affiliation data, where two people may be related if they belong to the same organizations. Sociologists have used affiliation data to compare formal membership, coded directly as ties between individuals and organizations, and the informal membership that can be gleaned from the relational structure of the formal ties. For Stark and Vedry, they are related if they are members of the same managing board {Vedres:2010gd}. 

As a practical concern, the two-mode format matches the raw data well. In the TR database citing and cited references are identified according to a different codification scheme. Though it is sometimes possible to recover some author, date, and journal information from reference codes, thorough covariates are measured only for citing articles.

Bipartite networks exhibit different patterns of clustering depending on whether they are projected in one mode or the other {Melamed:2014ft}.

It is often stated that a one-mode projection of two-mode data entails information loss, but this depends both on the ontology one associates with the data elements of a network and on whether one does the necessary bookkeeping to prevent the loss. In the co-reference network, ties represent the number of articles that used both citations in their references. In the co-article network, ties represent the number of citations two articles have in common. Data loss occurs both in the aggregation of ties and in the failure to recall that what is on one side of the coin a node is on the other a hyper tie or a ties connecting several nodes.

degreedist_table.pdf

paintedmode_projection.pdf

#### *Selection Effect on Populations* ####

Because they are each home to some of the oldest journals in the American social sciences, the University of Chicago Press and Wiley-Blackwell Inc. together account for the majority of cases in each category. Chicago makes up the largest share each of projects, references, and citations, surpassing the private publisher by about ten points in each category notwithstanding Wiley's lead in the number of journals and parity in the number of authors represented. The population share of a journal or publisher tends to be different after the selection effect, and it may also differs among its author, article, reference, and citation populations. For authors, the selection effect changes the distribution negligibly for the two leading publishers, but has noticeable effect on the representation of authors between the two professional organizations for Sociology and Economics, where authors of the former are more represented and of the latter less represented after network selection. Network selection has a substantial effect on Wiley Journals, the publisher being less represented in projects, pages, references, and citations. This indicates that projects from Wiley journals tend to less coherently connected to the larger citation network. By contrast, the AER increases its share of every population except pages, indicating that its projects are on average more coherently connected to the network. This is not necessarily the case for all Economics journals; the QJE in fact shows the biggest decline in cohesiveness, sling more than 6% of its references and citations after network selection.

How does this selection effect change over time?

#### *Results* ####

Is there something special about ASR, or Sage?

	![][1941i_s.pdf]

### **COMPUTATION** ###

### **DISCUSSION** ###

----

## **Chapter 3** ##

### **THEORY** ###

If black boxing is an important socio-cultural process in science, and perhaps other forms of scholarship, it will likely be implicated in network morphology. Black boxing is a process of closure, and closure implies detectable boundaries within a network of cultural communication. Whether closure is heralded as the progress of knowledge or its untimely demise, its effects will from a sociological standpoint be part and parcel of the more complicated structures of social stratification and field competition.

*Black Box* The term "black box" originated as a technical term in electrical engineering in the 1940s. It rapidly became a theory of knowledge in the early 1950s, appearing in popular science journals like Discovery and Popular Mechanics to characterize the awe that laymen felt when observing literal metal box housings for avionics or weapon targeting systems familiar especially to former servicemen in the 1950s and to a civilian audience fascinated by the technological feats of the war years. Whether the popular appearance of the term is analogous or homologous to its origins in the study of electrical circuits, the phrase connoted its meaning: between input and output wires, black boxes seemed to magically transform information into the control of practical problems. The visual metaphor was easily reinforced by the electronics revolution of the war years, which miniaturized especially the control components of industrial and commercial machines. A sublime attitude toward these small devices was possible only if one did not understand how they worked. The black box metaphor also quickly diffused within academia where it mapped neatly to the Skinnerian stimulus-response framework familiar to psychologists, being coined as a metaphor for the brain as early as a 1952 issue of Discovery {}. It was with some derision that information theorists in the 1950s began to adopt this metaphor to characterize the statistical approach to studying phenomena that were similarly opaque to observational researchers, who unlike engineers had not invented the "devices" they studied and who could therefore not claim to understand how they worked, knowing only that they worked in particular ways.

The term did not diffuse in the social sciences until the 1960s, during the first phase of the sociology of science. This attitude toward authority makes it clear that when science and technology scholars applied the black box term to the study of scientific practice, they did so paradoxically and in post-modern fashion. When the concept Latour{*Latour:1987ti} transforms the native understanding of the black box, which was a derisive attitude taken from popular science journals.

*As social hierarchy*. In the 1970s and since, the black box theory has appeared in the social sciences as a comment on method, sometimes as a prescription for the investigation of difficult problems and sometimes as a diagnosis of what is wrong with an approach. In its original incarnation as an orientation to technology (an artificial and well-ordered system), there is an aspect of the black box metaphor that is implicitly sociological; it applies only in a situation where an observer fails to comprehend a set of opaque phenomena that are assumed to account for the transparently systematic relationships among inputs and outputs. When such interior spaces are artificial, an inventor necessarily stands in a position of authority over the observer, who fails to apprehend what the inventor already knows, which is a full understanding of what the observer might learn about the exterior, and a substantial if not total understanding of what the observer will never learn about the interior. This is not to say that the box is utterly transparent to anyone, even the inventor, who indeed may often treat her product as a black box during the process of creation and when important problems are yet unsolved. Yet the ignorance of the observer is orders of magnitude more than the ignorance of the inventor, such that when comparing them, the box may be treated as black to one and transparent to the other. This knowledge asymmetry is a potential source of influence for the inventor (or other knowledgeable specialist), who may or may not choose to exploit her superior position. Insofar as the inventor accrues prestige on the basis of this asymmetry, she will enjoy whatever benefits are afforded by a felicitous status position in her social context. The interaction of observer and inventor is mediated by an interest in the box, and it is in the process of this three-way interaction that the social hierarchy between them is reproduced. Such hierarchies are interesting to sociologists because they are likely to have consequences "beyond the box".

	![][boxes.pdf]

	Figure X. Where 

A black box learning process ends when the observer correctly deigns the relationship of inputs to outputs, which may reframe the black box as a tool instead of a mystery, and good user oriented design will make for an easier learning curve. In this case the inventor's authority is abjured because the observer is able to enforce a utilitarian standard on the black box. Regarding it as a tool, the observer-cum-user renders irrelevant the secret knowledge of the design of the black box so long as the tool works as expected. When the black box breaks, the authority of the inventor may again become manifest in her relationship to the observer. Where secret knowledge is commodified such that the observer may easily pay for a repair or replacement to the black box, the influence of an inventor wanes in her relationship to the observer because there is no longer anything very special about her knowledge. It is something that can, like a lot of things, simply be purchased.

In the special case of a natural black box, where no inventor can claim to see inside the box, such social knowledge hierarchies are determined merely by positions on the learning curve for those studying its input and output relationships.

#### *Non-technological Case* ####

References as Black Box

#### *Morphology of Influence* ####

### **METHODS** ###

#### *Survival Analysis* ####

Problems: overlapping birth and death events of the underlying bearer of the culture will be treated as an uninterrupted duration of the cluster.

----

## **Chapter 4** ##

----

## **Conclusion** ##

Knowledge mapping as an alternative to creative destruction. Creative destruction may be functional

<<<<>>>>

[1941i_s.pdf]: 1941i_s.pdf width=612px height=792px

[boxes.pdf]: boxes.pdf width=314px height=189px

[^fn1]: There is some confusion in Boulding about whether complexity resides in the theory or in the phenomenon. His argument conflates concept and ontology, but suggests that it would be inappropriate to study a phenomenon of a given complexity using a theory of the wrong type. However it is routine in scientific investigation to reduce the complexity of the object to aid in human understanding, which is reflected in some scientists's tastes for parsimony.

[^fn2]: Later we will see that Lena and Peterson{*Lena:2008er} develop a framework of genre classification and then point toward a clockwork theory that would explain the mechanisms of transitions among categories.

[^fn3]: "Cultural capital (the same thing would be true, mutatis mutandis, of the economic game) determines the aggregate chances of profit in all the games in which cultural capital is effective, thereby helping to determine position in social space" {/*Bourdieu:1985wh/ :724}.

[^fn4]: As an observer a classification theorist applies the same categories ostensibly used by the observed, and has one foot in and one foot out of the reification trap described by Bourdieu. Lena and Peterson offer a stage sequential framework which, by their own admission {/*Lena:2008er/ :698}, implies unstudied mechanisms about how genres work. It treats genres as empirically knowable lacks the operational direction of the social space model.

[^fn5]: Though not all journals that are affiliated with a discipline signal this with a word containing the signature prefix, those that do are affiliated with a high degree of accuracy. Soci is an exception, and journals like the Royal Society of Statistics [madeup] are excluded.

[^fn6]: Often a reference to an author would not even include his first name. As scholarship professionalized reference behavior became more common, thorough, and accurate. Where the ratio of tacit to explicit references is high, the citation-based method pursued here will fail to capture the cultural boundaries at work, and another measure of meaningful affiliation, such as topic modeling of full text, would perform better. As the size and complexity of the scholarly stock of knowledge grew, citation behavior developed as a form of addressing in a larger world that was no longer familiar even to experts. Formal citations became normative between 19... and 19...In this early period prior to World War II,...